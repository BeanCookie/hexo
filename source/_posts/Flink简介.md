---
title: Flink简介
date: 2021-11-04 21:32:02
categories:
- Flink
tags: 
- Flink
---

### Flink是什么
根据Flink官网的定义，Flink是一个框架和分布式处理引擎，用于在**无边界**和**有边界**数据流上进行**有状态**的计算。Flink能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。
![https://beancookie.github.io/images/Flink简介-01.png](https://beancookie.github.io/images/Flink简介-01.png)


### Flink的起源
Apache Flink是Apache开源软件基金会的一个顶级项目，和许多Apache顶级项目一样，如Spark起源于UC伯克利的实验室，Flink也是起源于非常有名的
大学的实验室——柏林工业大学实验室。
项目最初的名称为Stratosphere，目标是要让大数据的处理看起来更加地简洁。
Stratosphere项目于2010年发起，2014年5月Stratosphere项目被贡献到Apache软件基金会，作为孵化器项目进行孵化并更名为Flink。发展至今，Flink已成为Apache社区最活跃的大数据项目。它的用户与开发者邮件列表活跃度在2020年的Apache年度报告中排名第一。

1. 社区邮件列表活跃度：TOP 1
![https://beancookie.github.io/images/Flink简介-02.png](https://beancookie.github.io/images/Flink简介-02.png)

2. Commits 提交：TOP 2
![https://beancookie.github.io/images/Flink简介-03.png](https://beancookie.github.io/images/Flink简介-03.png)

### 为什么要学习Apache Flink

1. 大数据处理的实时化趋势
随着网络迅速发展，大数据的处理呈现出非常明显的实时化趋势。
如上图所示，我们列举了一些现实生活中常见的场景。如春晚的直播有一个实时
大屏，双11购物节也有实时成交额的统计和媒体汇报。城市大脑可以实时监测交通，银行可以实时进行风控监测。当我们打开淘宝、天猫等应用软件时，它都会根据用户不同的习惯进行实时个性化推荐。

2. Flink已成为国内外实时计算事实标准
目前国内外许多公司都在使用 Flink，国际公司有 Netflix、eBay，LinkedIn 等，国内有阿里巴巴、腾讯、美团、小米、快手等大型互联网公司。
![https://beancookie.github.io/images/Flink简介-04.png](https://beancookie.github.io/images/Flink简介-04.png)

3. 随着流计算引擎的演进，Flink已成为新一代的计算引擎
- 流计算引擎进行了很多代的演进，第一代流计算引擎 Apache Storm 是一个纯流的设计，延迟非常的低，但是它的问题也比较明显，即没有办法避免消息的重复处理，从而导致数据正确性有一定的问题。

- Spark Streaming是第二代流计算引擎，解决了流计算语义正确性的问题，但是它的设计理念是以批为核心，最大的问题是延迟比较高，只能做到10秒级别的延迟，端到端无法实现秒以内的延迟。

- Flink 是第三代流计算引擎，也是最新一代的流计算引擎。它既可以保证低延迟，同时又可以保证消息的一致性语义，对于内置状态的管理，也极大降低了应用程序的复杂度。

### Apache Flink 典型应用场景

- 事件驱动型应用
事件驱动表示一个事件会触发另一个或者是很多个后续的事件，然后这一系列事
件会形成一些信息，基于这些信息需要做一定的处理。
在社交场景下，以微博为例当我们点击了一个关注之后，被关注人的粉丝数就
会发生变化。之后如果被关注的人发了一条微博，关注他的粉丝也会收到消息通知，这是一个典型的事件驱动。
总结一下，事件驱动型应用是一类具有状态的应用，会根据事件流中的事件触发
计算、更新状态或进行外部系统操作。事件驱动型应用常见于实时计算业务中，比
如：实时推荐，金融反欺诈，实时规则预警等。

- 数据分析型应用
第二类典型应用场景是数据分析型应用，如双11成交额实时汇总，包括
PV、UV 的统计。
还包括一些营销大屏，销量的升降，营销策略的结果进行环比、同比的比较，这
些背后都涉及到大量信息实时的分析和聚合，这些都是Flink非常典型的使用场景。
可以看到，这些应用的场景体量很大且对于实时性要求非常高，这也是
Apache Flink非常擅长的场景。

- 数据管道型应用 (ETL)
ETL（Extract-Transform-Load）是从数据源抽取/转换/加载/数据至目的端的过程。
传统的ETL使用离线处理，经常做的是小时级别或者天级别的ETL。但是随着大数据处理呈现实时化趋势，我们也会有实时数仓的需求，要求在分钟级或者秒级就能够对数据进行更新，从而进行及时的查询，能够看到实时的指标，然后做更实时的判断和分析。