---
title: 一致性哈希算法
date: 2020-08-03 11:25:50
categories:
- 缓存
tags: 
- 一致性哈希
---

#### 非加密哈希算法

在加密或者信息摘要中经常会使用到MD5、SHA之类的哈希算法，这类哈希算法最主要的特性就是不可逆以及需要线性的加密时间，这样就可以增加篡改和破解难度。非加密算法追求的则是计算哈希值的速度以及减少冲突率。

#### 基本概念

- 哈希值

  无论是内存容器中的下标位置还是分布式环境下的节点位置都可以通过哈希值定位，最简单的实现方式如下：如果是整数类型的key值可以通过取模获取哈希值，字符串可以通过叠加乘法获取哈希值

  ```java
   private static int getHashCode(int value, int mod) {
       return Math.abs(value % mod);
   }
  
  private static int getHashCode(String value) {
      if (Objects.isNull(value)) {
          return 0;
      }
      int h = 0;
      for (char ch : value.toCharArray()) {
          h = 31 * h + ch;
      }
      return h;
  }
  
  @Test
  void javaHashTest() {
      System.out.println(getHashCode(24, 16)); // 8
      System.out.println(getHashCode("abcd")); // 2987074
      System.out.println(getHashCode("abce")); // 2987075
      System.out.println(getHashCode("192.168.1.177")); // -2051273035
      System.out.println(getHashCode("192.168.1.178")); // -2051273034
  }
  ```

- 哈希碰撞

  因为不同key值的哈希值有可能相同，所以会有一定概率出现哈希冲突的情况，通常有两个解决哈希冲突的方式：拉链法和开发地址法

  ![一致性哈希算法-01](https://beancookie.github.io/images/一致性哈希算法-01.png)

  ![一致性哈希算法-02](https://beancookie.github.io/images/一致性哈希算法-02.png)

- 负载因子

  最大可容纳的数据量与容器实际大小的比值就是负载因子，经研究发现负载因子与冲突率成正比，通常情况下将负载因子设为0.75是性价比最高的做法

  ![一致性哈希算法-03](https://beancookie.github.io/images/一致性哈希算法-03.png)

#### 几种高效的哈希算法

- MurmurHash

  > MurmurHash因其出色的性能，已经被Redis，Memcached，Cassandra，HBase，Lucene等著名项目采用

  ```java
  private static int mix32(int k, int hash) {
      k *= -862048943;
      k = Integer.rotateLeft(k, 15);
      k *= 461845907;
      hash ^= k;
      return Integer.rotateLeft(hash, 13) * 5 + -430675100;
  }
  
  private static int fmix32(int length, int hash) {
      hash ^= length;
      hash ^= hash >>> 16;
      hash *= -2048144789;
      hash ^= hash >>> 13;
      hash *= -1028477387;
      hash ^= hash >>> 16;
      return hash;
  }
  
  public static int hash32(byte[] data, int offset, int length, int seed) {
      int hash = seed;
      int nblocks = length >> 2;
  
      int idx;
      int k1;
      for(idx = 0; idx < nblocks; ++idx) {
          k1 = idx << 2;
          int k = data[offset + k1] & 255 | (data[offset + k1 + 1] & 255) << 8 | (data[offset + k1 + 2] & 255) << 16 | (data[offset + k1 + 3] & 255) << 24;
          hash = mix32(k, hash);
      }
  
      idx = nblocks << 2;
      k1 = 0;
      switch(length - idx) {
          case 3:
              k1 ^= data[offset + idx + 2] << 16;
          case 2:
              k1 ^= data[offset + idx + 1] << 8;
          case 1:
              k1 ^= data[offset + idx];
              k1 *= -862048943;
              k1 = Integer.rotateLeft(k1, 15);
              k1 *= 461845907;
              hash ^= k1;
          default:
              return fmix32(length, hash);
      }
  }
  
  public static int hash32(String data) {
      byte[] origin = data.getBytes();
      return hash32(origin, 0, origin.length, 104729);
  }
  
  
  
  @Test
  void murmurHashTest() {
      System.out.println(hash32("abcd"));
  }
  ```

#### 普通哈希算法在分布式环境下的弊端

已数据分库为例，假设我们将一个user表拆分到4个库，利用user_id % 4进行分发。如果此时需要扩容一台数据库5

- 扩容前

| 数据库 | user_id             | 哈希值 |
| ------ | ------------------- | ------ |
| 1      | 1000,1004,1008,1012 | 0      |
| 2      | 1001,1005,1009,1013 | 1      |
| 3      | 1002,1006,1010,1014 | 2      |
| 4      | 1003,1007,1011      | 3      |

- 扩容后

| 数据库 | user_id        | 哈希值 |
| ------ | -------------- | ------ |
| 1      | 1000,1005,1010 | 0      |
| 2      | 1001,1006,1011 | 1      |
| 3      | 1002,1007,1012 | 2      |
| 4      | 1003,1008,1013 | 3      |
| 5      | 1004,1009,1014 | 4      |

这时会发现调整后有大量的user对应的数据库与调整期不一致，此时如果想要保证数据可用则需要进行大量的数据迁移。

#### 一致性哈希算法原理

一致性哈希算法就是为了解决分布式环境下普通哈希算法的弊端，其目的就是为了能够在扩容或者缩容时尽量减少数据迁移。因为通常情况下哈希值都是使用int四字节的整数进行存储的，所以就选用0~2^31-1这么一个无符号整形的数据范围抽象的表示出一个哈希环。

![一致性哈希算法-06](https://beancookie.github.io/images/一致性哈希算法-06.png)

然后将数据库所在服务器的IP地址，或者是相关服务的IP+端口号经过某种Hash函数获取到对应的哈希值，通过此哈希值映射到哈希环的某个位置。当请求数据比如此处的user_id到达服务端时，也通过同样的Hash函数获取到对应的哈希值，通过这个哈希值顺时针获取到最近的服务位置。

![一致性哈希算法-04](https://beancookie.github.io/images/一致性哈希算法-04.png)

这样做的优点是什么呢？

1. 当我们需要扩容时，正好扩容的机器11.1.211.8:8080被分配到了11.1.211.1:8080前面，扩容之后受影响的机器只有11.1.211.1:8080这一台，只需要将11.1.211.8:8080~11.1.211.1:8080之间的这部分user数据迁移到11.1.211.8:8080上，对其他节点并不会产生影响。

   ![一致性哈希算法-07](https://beancookie.github.io/images/一致性哈希算法-07.png)

2. 当我们需要缩容时，例如我们需要移除11.1.211.1:8080，那么只需要将11.1.211.7:8080~11.1.211.1:8080之间的user数据迁移到11.1.211.2:8080上就可以了。

   ![一致性哈希算法-08](https://beancookie.github.io/images/一致性哈希算法-08.png)

##### 数据倾斜问题

当哈希环中的服务节点分布不均时，很容易造成大量数据堆积到某个节点，而其他节点只能接收到少量数据。

![一致性哈希算法-09](https://beancookie.github.io/images/一致性哈希算法-09.png)

##### 虚拟节点

这时就可以对一个服务节点的IP地址添加一定的标识数据计算多个Hash函数，例如

```java
hash("11.1.211.1#A") % 2^32
hash("11.1.211.2#B") % 2^32
```

这时就可以增加哈希环中的节点数量使得节点分布更加均匀，但是虚拟节点的数据依然会被存储到对应的真是节点，并不影响整体结构。

![一致性哈希算法-10](https://beancookie.github.io/images/一致性哈希算法-10.png)